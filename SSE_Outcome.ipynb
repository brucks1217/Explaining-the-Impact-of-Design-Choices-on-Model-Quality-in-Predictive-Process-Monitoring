{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import operator\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import joblib\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "random.seed(42)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncate Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_trun(log, min_thres, max_thres_p):\n",
    "    case_count = log[caseid].value_counts()\n",
    "    max_len = np.quantile(case_count.values, max_thres_p)\n",
    "    if np.quantile(case_count.values,0.25) < min_thres:\n",
    "        min_len = 2 \n",
    "    else:\n",
    "        min_len = min_thres\n",
    "    case_keep = case_count[( case_count >min_len ) & ( case_count <= max_len )].index.tolist()\n",
    "    log = log[log[caseid].isin(case_keep)]\n",
    "    log.reset_index(drop=True, inplace=True)\n",
    "    return log, min_len, max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_feat(log, comb):\n",
    "    if comb == 'all':\n",
    "        pass\n",
    "    elif comb == 'tssc_tsp':\n",
    "        log[[wk,tmd]] = 0\n",
    "    elif comb == 'none':\n",
    "        log[[wk,tmd,tssc,tsp]] = 0\n",
    "    else:\n",
    "        print(\"Wrong Input\")\n",
    "        return None\n",
    "    return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_enc(log,method,win_size,pad_size):\n",
    "    input_idx = 0\n",
    "    input_id = 'Input ID'\n",
    "    cols_ = log.columns.tolist()\n",
    "    cols_.append(input_id)\n",
    "    encoded_df = pd.DataFrame(columns=cols_)\n",
    "    for c, t in log.groupby(caseid):\n",
    "        for ts in range(min_size,len(t)):\n",
    "            if method == 'cont': \n",
    "                trc_ = pd.DataFrame()\n",
    "                trc_ = copy.deepcopy(t.iloc[(ts-5):ts])\n",
    "                trc_[input_id] = input_idx\n",
    "                encoded_df = pd.concat([encoded_df, trc_],ignore_index=True)\n",
    "            elif method == 'prfx': \n",
    "                trc_ = pd.DataFrame()\n",
    "                trc_ = copy.deepcopy(t.iloc[:ts])\n",
    "                zero_rows = pd.DataFrame(np.zeros((int(max_size-trc_.shape[0]), trc_.shape[1])), columns=trc_.columns)\n",
    "                zero_rows[act] = 'zero_pad'\n",
    "                trc_ = pd.concat([trc_, zero_rows], ignore_index=True)\n",
    "                trc_[input_id] = input_idx\n",
    "                trc_[caseid] = t[caseid].iloc[ts]\n",
    "                encoded_df = pd.concat([encoded_df, trc_], ignore_index=True)\n",
    "            elif method == 'se': \n",
    "                trc_ = pd.DataFrame()\n",
    "                trc_ = copy.deepcopy(t.iloc[[ts-1]])\n",
    "                trc_[input_id] = input_idx\n",
    "                encoded_df = pd.concat([encoded_df, trc_], ignore_index=True)\n",
    "            else:\n",
    "                print(\"Wrong Input\")\n",
    "            input_idx += 1\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_minmax(log,comb):\n",
    "    scaler = MinMaxScaler()\n",
    "    if comb == 'all':\n",
    "        log[[wk,tmd,tssc,tsp]] = scaler.fit_transform(log[[wk,tmd,tssc,tsp]])\n",
    "    elif comb == 'tssc_tsp':\n",
    "        log[[wk,tmd,tssc,tsp]] = scaler.fit_transform(log[[wk,tmd,tssc,tsp]])\n",
    "    elif comb == 'none':\n",
    "        log[[wk,tmd,tssc,tsp]] = scaler.fit_transform(log[[wk,tmd,tssc,tsp]])\n",
    "    else:\n",
    "        print(\"Wrong Input\")\n",
    "        return None\n",
    "    return log\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event Encoding1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evt_enc1(log,comb):\n",
    "    if comb == 'emb':\n",
    "        unique_act = log[act].unique()\n",
    "        act_to_idx = {a: i for i, a in enumerate(unique_act)}\n",
    "        log[act] = log[act].map(act_to_idx)\n",
    "    elif comb == 'oh':\n",
    "        org_col = log.columns\n",
    "        log = pd.get_dummies(copy.deepcopy(log), columns=[act],dtype=int)\n",
    "        oh_col = log.columns\n",
    "        oh_act = list(set(oh_col)-set(org_col))\n",
    "    elif comb == 'frq':\n",
    "        org_col = log.columns\n",
    "        log = pd.get_dummies(copy.deepcopy(log), columns=[act],dtype=int)\n",
    "        oh_col = log.columns\n",
    "        oh_act = list(set(oh_col)-set(org_col))\n",
    "        frq_df1 = log[[label,'Input ID',caseid]].groupby('Input ID').max()\n",
    "        frq_df2 = log[oh_act+['Input ID']+[wk,tmd,tssc,tsp]].groupby('Input ID').sum()\n",
    "        log = frq_df1.join(frq_df2)\n",
    "        log = log.reset_index()\n",
    "        log[list(set([wk,tmd,tssc,tsp])-set(log.columns)&set([wk,tmd,tssc,tsp]))] = 0\n",
    "    return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_split(log1,log2,ratio):\n",
    "    random.seed(42)\n",
    "    split_ = list(log1[caseid].unique())\n",
    "    random.shuffle(split_)\n",
    "    split_ = split_[:int(len(split_)*ratio)]\n",
    "    train_log = log2[log2[caseid].isin(split_)]\n",
    "    test_log = log2[~(log2[caseid].isin(split_))]\n",
    "    if sorted(list(set(list(train_log[act].unique()))&set(list(test_log[act].unique())))) != sorted(set(list(test_log[act].unique()))):\n",
    "        ex_act = list(set(list(test_log[act].unique()))-set(list(train_log[act].unique()))&set(list(test_log[act].unique())))\n",
    "        del_case = log1[log1[caseid].isin(log2[log2[act].isin(ex_act)][caseid].values)].index.tolist()\n",
    "        log1.drop(del_case,inplace=True)\n",
    "        train_log = log1[log1[caseid].isin(split_)]\n",
    "        test_log = log1[~(log1[caseid].isin(split_))]\n",
    "    else:\n",
    "        train_log = log1[log1[caseid].isin(split_)]\n",
    "        test_log = log1[~(log1[caseid].isin(split_))]\n",
    "    val_case = random.sample(list(train_log[caseid].unique()),int(round(train_log[caseid].nunique()/4,0)))\n",
    "    val_log = train_log[train_log[caseid].isin(val_case)]    \n",
    "    train_log = train_log[~train_log[caseid].isin(val_case)]\n",
    "    return train_log, test_log, val_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorset(log,comb,cols):\n",
    "    act_list =[]\n",
    "    time_list = []\n",
    "    label_list = []\n",
    "    for c, t in log.groupby('Input ID'):\n",
    "        if comb == 'emb':\n",
    "            act_list.append(t[act].values.reshape(1,-1).tolist())\n",
    "            label_list.append(np.array(list(set(t[label].values))).reshape(1,-1).tolist())\n",
    "            time_list.append(t[[wk,tmd,tssc,tsp]].values.reshape(1,-1).tolist())\n",
    "        elif comb == 'oh':\n",
    "            act_list.append(t[cols].values.reshape(1,-1).tolist())\n",
    "            lab_temp, _ = Counter(t[label].values.tolist()).most_common(1)[0]\n",
    "            label_list.append([[lab_temp]])\n",
    "            time_list.append(t[[wk,tmd,tssc,tsp]].values.reshape(1,-1).tolist())\n",
    "        elif comb == 'frq':\n",
    "            act_list.append(t[cols].values.reshape(1,-1).tolist())\n",
    "            lab_temp, _ = Counter(t[label].values.tolist()).most_common(1)[0]\n",
    "            label_list.append([[lab_temp]])\n",
    "            time_list.append(t[[wk,tmd,tssc,tsp]].values.reshape(1,-1).tolist())\n",
    "    if comb == 'emb':\n",
    "        act_tensor = torch.tensor(act_list, dtype=torch.int64)\n",
    "        label_tensor = torch.tensor(label_list, dtype=torch.float)\n",
    "        time_tensor = torch.tensor(time_list, dtype=torch.float) \n",
    "        ts = TensorDataset(act_tensor, time_tensor, label_tensor)\n",
    "        dl = DataLoader(ts, batch_size=16, shuffle=True)\n",
    "    elif (comb == 'oh') or (comb == 'frq'):\n",
    "        act_tensor = torch.tensor(act_list, dtype=torch.float)\n",
    "        label_tensor = torch.tensor(label_list, dtype=torch.float)\n",
    "        time_tensor = torch.tensor(time_list, dtype=torch.float)\n",
    "        ts = TensorDataset(act_tensor, time_tensor, label_tensor)\n",
    "        dl = DataLoader(ts, batch_size=16, shuffle=True)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mldataset(log):\n",
    "    y_bin = []\n",
    "    x_bin = []\n",
    "    for ipid, ipr in log.groupby('Input ID'):\n",
    "        y_temp,_ = Counter(ipr[label].values.tolist()).most_common(1)[0]\n",
    "        y_bin.append([y_temp])\n",
    "        x_bin.extend((ipr[flat_col].values.reshape(1, -1).tolist()))\n",
    "    x_set = np.array(x_bin)\n",
    "    y_set = np.array(y_bin)\n",
    "    return x_set,y_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTMModel(nn.Module):\n",
    "    def __init__(self, act_size, time_feature_dim, hidden_dim, output_dim, num_layers, comb2, comb3):\n",
    "        super(MyLSTMModel, self).__init__()\n",
    "        self.mod = comb2\n",
    "        self.evmod = comb3\n",
    "        self.main_layers = nn.ModuleList()\n",
    "        if self.evmod =='oh': \n",
    "            for i in range(num_layers):\n",
    "                self.main_layers.append(nn.LSTM(int(act_size/(time_feature_dim/4)) if i == 0 else hidden_dim, hidden_dim, batch_first=True))\n",
    "                self.main_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "        elif self.evmod == 'frq':\n",
    "            for i in range(num_layers):\n",
    "                self.main_layers.append(nn.LSTM(act_size if i == 0 else hidden_dim, hidden_dim, batch_first=True))\n",
    "                self.main_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.actf = nn.Tanh()\n",
    "        for mlayer in self.main_layers:\n",
    "            if isinstance(mlayer, nn.LSTM):\n",
    "                for name, param in mlayer.named_parameters():\n",
    "                    if 'weight_ih' in name:\n",
    "                        nn.init.xavier_uniform_(param.data)\n",
    "                    elif 'weight_hh' in name:\n",
    "                        nn.init.xavier_uniform_(param.data)\n",
    "    def forward(self, feature1, feature2):\n",
    "        if self.evmod =='oh':\n",
    "            layer_out = feature1.view(feature1.shape[0], int(feature2.shape[2]/4), int(feature1.shape[2]/(feature2.shape[2]/4)))\n",
    "        elif self.evmod == 'frq':\n",
    "            layer_out = feature1\n",
    "        for i in range(0, len(self.main_layers), 2):\n",
    "            mlayer = self.main_layers[i]\n",
    "            bn = self.main_layers[i+1]\n",
    "            layer_out, _ = mlayer(layer_out)\n",
    "            layer_out = layer_out.permute(0, 2, 1)  \n",
    "            layer_out = bn(layer_out)\n",
    "            layer_out = layer_out.permute(0, 2, 1)  \n",
    "        output = self.fc(layer_out[:, -1, :])\n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLPModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(MyMLPModel, self).__init__()\n",
    "        self.main_layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.main_layers.append(nn.Linear(input_size if i == 0 else hidden_size, hidden_size))\n",
    "            self.main_layers.append(nn.BatchNorm1d(hidden_size))\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.actf = nn.Tanh()\n",
    "        for mlayer in self.main_layers:\n",
    "            if isinstance(mlayer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(mlayer.weight)\n",
    "                if mlayer.bias is not None:\n",
    "                    nn.init.constant_(mlayer.bias, 0)\n",
    "    def forward(self, x):\n",
    "        layer_out = x\n",
    "        for i in range(0, len(self.main_layers), 2):\n",
    "            mlayer = self.main_layers[i]\n",
    "            bn = self.main_layers[i+1]\n",
    "            layer_out = mlayer(layer_out)\n",
    "            layer_out = layer_out.permute(0, 2, 1)  \n",
    "            layer_out = bn(layer_out)\n",
    "            layer_out = layer_out.permute(0, 2, 1)  \n",
    "            layer_out = self.actf(layer_out)\n",
    "        output = self.fc(layer_out[:, -1, :])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstmobjective(trial):\n",
    "    \n",
    "    hidden_size = trial.suggest_int('hidden_size', 16, 256,step = 16, log=False)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2,step = 5*1e-5, log=False)\n",
    "    model = MyLSTMModel(act_size = act_in_shape, time_feature_dim=time_in_shape, hidden_dim=hidden_size, \n",
    "                        output_dim=1, num_layers=num_layers,  comb2 = model_mtd, comb3 = ev_mtd).to(device)\n",
    "    prstr = '_'.join(str(value) for value in trial.params.values())\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    early_loss = np.Inf\n",
    "    early_count = 0\n",
    "    model.train()\n",
    "    for epoch in range(50): \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for feature1, feature2, lab_load in train_loader:  \n",
    "            feature1, feature2, lab_load = feature1.to(device), feature2.to(device), lab_load.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(feature1, feature2)\n",
    "            lab_load = lab_load.squeeze()\n",
    "            if lab_load.dim() == 0:\n",
    "                lab_load = lab_load.unsqueeze(0)\n",
    "            loss = criterion(outputs.squeeze(), lab_load.float())  \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * feature1.size(0)\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for feature1, feature2, lab_load in valid_loader:\n",
    "                feature1, feature2, lab_load = feature1.to(device), feature2.to(device), lab_load.to(device)\n",
    "                outputs = model(feature1, feature2 )\n",
    "                lab_load = lab_load.squeeze()\n",
    "                if lab_load.dim() == 0:\n",
    "                    lab_load = lab_load.unsqueeze(0)\n",
    "                loss = criterion(outputs.squeeze(), lab_load.float())  \n",
    "                valid_loss += loss.item() * feature1.size(0)\n",
    "        valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "        if valid_loss < early_loss:\n",
    "            early_loss = valid_loss\n",
    "            torch.save(model.state_dict(), model_loc+f'lstm_model_{prstr}.pt')\n",
    "            best_epoch = epoch\n",
    "        elif valid_loss >= early_loss:\n",
    "            if early_count > 5:\n",
    "                break\n",
    "            early_count+= 1    \n",
    "\n",
    "    pred_auc = np.empty((0, 1))\n",
    "    true_auc = np.array([])\n",
    "    model.load_state_dict(torch.load(model_loc+f'lstm_model_{prstr}.pt'))\n",
    "    model.eval()\n",
    "    pred_acc_bin, true_acc = [], []\n",
    "    with torch.no_grad():\n",
    "        for feature1, feature2, lab_load in valid_loader:\n",
    "            feature1, feature2, lab_load = feature1.to(device), feature2.to(device), lab_load.to(device)\n",
    "            outputs = model(feature1, feature2)\n",
    "            lab_load = lab_load.squeeze()\n",
    "            if lab_load.dim() == 0:\n",
    "                lab_load = lab_load.unsqueeze(0)                                    \n",
    "\n",
    "            pred_acc = torch.sigmoid(outputs).round().squeeze().tolist()\n",
    "            pred_auc = np.vstack((pred_auc, torch.sigmoid(outputs).detach().cpu().numpy()))\n",
    "            if true_auc.size == 0:\n",
    "                true_auc = lab_load.unsqueeze(1).cpu().numpy()\n",
    "            else:\n",
    "                true_auc = np.concatenate((true_auc, lab_load.unsqueeze(1).cpu().numpy()))\n",
    "\n",
    "            pred_acc_bin.extend(pred_acc)\n",
    "            true_acc.extend(lab_load.tolist())\n",
    "    \n",
    "    accuracy = accuracy_score(true_acc, pred_acc_bin)\n",
    "    \n",
    "    auc = roc_auc_score(true_auc, pred_auc)\n",
    "    return (auc+accuracy)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlpobjective(trial):\n",
    "\n",
    "    hidden_size = trial.suggest_int('hidden_size', 16, 256,step = 16, log=False)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2,step = 5*1e-5, log=False)\n",
    "    \n",
    "    model = MyMLPModel(input_size=act_in_shape, hidden_size=hidden_size, num_layers=num_layers, output_size=1).to(device)\n",
    "    \n",
    "    prstr = '_'.join(str(value) for value in trial.params.values())\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    early_loss = np.Inf\n",
    "    early_count = 0\n",
    "    model.train()\n",
    "    for epoch in range(50): \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for feature1, lab_load in train_loader:  \n",
    "            feature1, lab_load = feature1.to(device),lab_load.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(feature1)\n",
    "            lab_load = lab_load.squeeze()\n",
    "            if lab_load.dim() == 0:\n",
    "                lab_load = lab_load.unsqueeze(0)\n",
    "            loss = criterion(outputs.squeeze(), lab_load.float())  \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * feature1.size(0)\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for feature1, lab_load in valid_loader:\n",
    "                feature1, lab_load = feature1.to(device), lab_load.to(device)\n",
    "                outputs = model(feature1 )\n",
    "                lab_load = lab_load.squeeze()\n",
    "                if lab_load.dim() == 0:\n",
    "                    lab_load = lab_load.unsqueeze(0)\n",
    "                loss = criterion(outputs.squeeze(), lab_load.float())  \n",
    "\n",
    "                valid_loss += loss.item() * feature1.size(0)\n",
    "        valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "        if valid_loss < early_loss:\n",
    "            early_loss = valid_loss\n",
    "            torch.save(model.state_dict(), model_loc+f'mlp_model_{prstr}.pt')\n",
    "            best_epoch = epoch\n",
    "        elif valid_loss >= early_loss:\n",
    "            if early_count > 5:\n",
    "                break\n",
    "            early_count+= 1    \n",
    "\n",
    "    pred_auc = np.empty((0, 1))\n",
    "    true_auc = np.array([])\n",
    "    model.load_state_dict(torch.load(model_loc+f'mlp_model_{prstr}.pt'))\n",
    "    model.eval()\n",
    "    pred_acc_bin, true_acc = [], []\n",
    "    with torch.no_grad():\n",
    "        for feature1, lab_load in valid_loader:\n",
    "            feature1, lab_load = feature1.to(device), lab_load.to(device)\n",
    "            outputs = model(feature1)\n",
    "            lab_load = lab_load.squeeze()\n",
    "            if lab_load.dim() == 0:\n",
    "                lab_load = lab_load.unsqueeze(0)                                    \n",
    "\n",
    "            pred_acc = torch.sigmoid(outputs).round().squeeze().tolist()\n",
    "            pred_auc = np.vstack((pred_auc, torch.sigmoid(outputs).detach().cpu().numpy()))\n",
    "            if true_auc.size == 0:\n",
    "                true_auc = lab_load.unsqueeze(1).cpu().numpy()\n",
    "            else:\n",
    "                true_auc = np.concatenate((true_auc, lab_load.unsqueeze(1).cpu().numpy()))\n",
    "\n",
    "            pred_acc_bin.extend(pred_acc)\n",
    "            true_acc.extend(lab_load.tolist())\n",
    "    \n",
    "    accuracy = accuracy_score(true_acc, pred_acc_bin)\n",
    "    auc = roc_auc_score(true_auc, pred_auc)\n",
    "    return (auc+accuracy)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbobjective(trial):\n",
    "    \n",
    "    param = {\n",
    "        'verbosity': 0,\n",
    "        'objective': 'binary:logistic',\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 32),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1.0,step = 5*1e-5, log=False),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 300),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "    }\n",
    "\n",
    "    clf = xgb.XGBClassifier(**param)\n",
    "    clf.fit(train_x, train_y.ravel())\n",
    "\n",
    "    prstr = '_'.join(str(value) for value in trial.params.values())\n",
    "    clf.save_model(model_loc+f'xgb_model_{prstr}.json')\n",
    "    \n",
    "    preds_acc = clf.predict(valid_x)\n",
    "    preds_auc = clf.predict_proba(valid_x)[:, 1]\n",
    "    auc = roc_auc_score(valid_y, preds_auc)\n",
    "    acc = accuracy_score(valid_y, preds_acc)\n",
    "    return (acc+auc)/2\n",
    "\n",
    "def adbobjective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 32)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 300,step = 5, log=False)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1.0,step = 5*1e-5, log=False)\n",
    "    \n",
    "    base_estimator = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    \n",
    "    clf = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=max_depth),\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        random_state=42)\n",
    "\n",
    "    clf.fit(train_x, train_y.ravel())\n",
    "    \n",
    "    prstr = '_'.join(str(value) for value in trial.params.values())\n",
    "    joblib.dump(clf, model_loc+f'adb_model_{prstr}.pkl')\n",
    "        \n",
    "    preds_acc = clf.predict(valid_x)\n",
    "    preds_auc = clf.predict_proba(valid_x)[:, 1]\n",
    "    auc = roc_auc_score(valid_y, preds_auc)\n",
    "    acc = accuracy_score(valid_y, preds_acc)\n",
    "    return (acc+auc)/2\n",
    "\n",
    "\n",
    "def rfobjective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 300,step = 5, log=False)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    \n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth, \n",
    "        min_samples_split=min_samples_split, \n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42)\n",
    "    clf.fit(train_x, train_y.ravel())\n",
    "\n",
    "    prstr = '_'.join(str(value) for value in trial.params.values())\n",
    "    joblib.dump(clf, model_loc+f'rf_model_{prstr}.pkl')\n",
    "    \n",
    "    preds_acc = clf.predict(valid_x)\n",
    "    preds_auc = clf.predict_proba(valid_x)[:, 1]\n",
    "    auc = roc_auc_score(valid_y, preds_auc)\n",
    "    acc = accuracy_score(valid_y, preds_acc)\n",
    "    return (acc+auc)/2\n",
    "\n",
    "\n",
    "def dtobjective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    max_features = trial.suggest_float('max_features', 0.1, 1.0)\n",
    "    \n",
    "    clf = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=42)\n",
    "    clf.fit(train_x, train_y.ravel())\n",
    "\n",
    "    prstr = '_'.join(str(value) for value in trial.params.values())\n",
    "    joblib.dump(clf, model_loc+f'dt_model_{prstr}.pkl')\n",
    "    \n",
    "    preds_acc = clf.predict(valid_x)\n",
    "    preds_auc = clf.predict_proba(valid_x)[:, 1]\n",
    "    auc = roc_auc_score(valid_y, preds_auc)\n",
    "    acc = accuracy_score(valid_y, preds_acc)\n",
    "    return (acc+auc)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EarlyStop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingCallback(object):\n",
    "    def __init__(self, early_stopping_rounds: int, direction: str) -> None:\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self._iter = 0\n",
    "        if direction == \"minimize\":\n",
    "            self._operator = operator.lt\n",
    "            self._score = np.inf\n",
    "        elif direction == \"maximize\":\n",
    "            self._operator = operator.gt\n",
    "            self._score = -np.inf\n",
    "        else:\n",
    "            ValueError(f\"invalid direction: {direction}\")\n",
    "\n",
    "    def __call__(self, study: optuna.Study, trial: optuna.Trial) -> None:\n",
    "        if self._operator(study.best_value, self._score):\n",
    "            self._iter = 0\n",
    "            self._score = study.best_value\n",
    "        else:\n",
    "            self._iter += 1\n",
    "        if self._iter >= self.early_stopping_rounds:\n",
    "            study.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ObtunaTEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstmtest(lstmparam):\n",
    "    prteststr = '_'.join(str(value) for value in lstmparam.values())\n",
    "    model = MyLSTMModel(act_size=act_in_shape, time_feature_dim=time_in_shape, hidden_dim=lstmparam['hidden_size'],\n",
    "                        num_layers=lstmparam['num_layers'], output_dim=1,  comb2 = model_mtd, comb3 = ev_mtd).to(device)\n",
    "    pred_auc = np.empty((0, 1))\n",
    "    true_auc = np.array([])\n",
    "    model.load_state_dict(torch.load(model_loc+f'lstm_model_{prteststr}.pt'))\n",
    "    model.eval()\n",
    "    pred_acc_bin, true_acc = [], []\n",
    "    with torch.no_grad():\n",
    "        for feature1, feature2, lab_load in test_loader:\n",
    "            feature1, feature2, lab_load = feature1.to(device), feature2.to(device), lab_load.to(device)\n",
    "            outputs = model(feature1, feature2)\n",
    "            lab_load = lab_load.squeeze()\n",
    "            if lab_load.dim() == 0:\n",
    "                lab_load = lab_load.unsqueeze(0)                                    \n",
    "\n",
    "            pred_acc = torch.sigmoid(outputs).round().squeeze().tolist()\n",
    "            pred_acc_bin.extend(pred_acc)\n",
    "            true_acc.extend(lab_load.tolist())\n",
    "            \n",
    "            pred_auc = np.vstack((pred_auc, torch.sigmoid(outputs).detach().cpu().numpy()))\n",
    "            if true_auc.size == 0:\n",
    "                true_auc = lab_load.unsqueeze(1).cpu().numpy()\n",
    "            else:\n",
    "                true_auc = np.concatenate((true_auc, lab_load.unsqueeze(1).cpu().numpy()))\n",
    "    acc = accuracy_score(true_acc, pred_acc_bin)\n",
    "    auc = roc_auc_score(true_auc, pred_auc)\n",
    "    return auc,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlptest(mlpparam):\n",
    "    prteststr = '_'.join(str(value) for value in mlpparam.values())\n",
    "    model = MyMLPModel(input_size=act_in_shape, hidden_size=mlpparam['hidden_size'], num_layers=mlpparam['num_layers'], output_size=1).to(device)\n",
    "    pred_auc = np.empty((0, 1))\n",
    "    true_auc = np.array([])\n",
    "    model.load_state_dict(torch.load(model_loc+f'mlp_model_{prteststr}.pt'))\n",
    "    model.eval()\n",
    "    pred_acc_bin, true_acc = [], []\n",
    "    with torch.no_grad():\n",
    "        for feature1, lab_load in test_loader:\n",
    "            feature1, lab_load = feature1.to(device), lab_load.to(device)\n",
    "            outputs = model(feature1)\n",
    "            lab_load = lab_load.squeeze()\n",
    "            if lab_load.dim() == 0:\n",
    "                lab_load = lab_load.unsqueeze(0)                                    \n",
    "\n",
    "            pred_acc = torch.sigmoid(outputs).round().squeeze().tolist()\n",
    "            pred_acc_bin.extend(pred_acc)\n",
    "            true_acc.extend(lab_load.tolist())\n",
    "            \n",
    "            pred_auc = np.vstack((pred_auc, torch.sigmoid(outputs).detach().cpu().numpy()))\n",
    "            if true_auc.size == 0:\n",
    "                true_auc = lab_load.unsqueeze(1).cpu().numpy()\n",
    "            else:\n",
    "                true_auc = np.concatenate((true_auc, lab_load.unsqueeze(1).cpu().numpy()))\n",
    "\n",
    "    acc = accuracy_score(true_acc, pred_acc_bin)\n",
    "    auc = roc_auc_score(true_auc, pred_auc)\n",
    "    return auc,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbtest(xgbparam):\n",
    "    prteststr = '_'.join(str(value) for value in xgbparam.values())\n",
    "    clf = xgb.XGBClassifier()\n",
    "    clf.load_model(model_loc+f'xgb_model_{prteststr}.json')    \n",
    "    preds_auc = clf.predict_proba(test_x)[:, 1]\n",
    "    preds_acc = clf.predict(test_x)\n",
    "    auc = roc_auc_score(test_y, preds_auc)\n",
    "    acc = accuracy_score(test_y, preds_acc)\n",
    "    return auc,acc\n",
    "\n",
    "def adbtest(adbparam):\n",
    "    prteststr = '_'.join(str(value) for value in adbparam.values())\n",
    "    clf = joblib.load(model_loc+f'adb_model_{prteststr}.pkl')\n",
    "    preds_auc = clf.predict_proba(test_x)[:, 1]\n",
    "    preds_acc = clf.predict(test_x)\n",
    "    auc = roc_auc_score(test_y, preds_auc)\n",
    "    acc = accuracy_score(test_y, preds_acc)\n",
    "    return auc,acc\n",
    "\n",
    "def rftest(rfparam):\n",
    "    prteststr = '_'.join(str(value) for value in rfparam.values())\n",
    "    clf = joblib.load(model_loc+f'rf_model_{prteststr}.pkl')\n",
    "    preds_auc = clf.predict_proba(test_x)[:, 1]\n",
    "    preds_acc = clf.predict(test_x)\n",
    "    auc = roc_auc_score(test_y, preds_auc)\n",
    "    acc = accuracy_score(test_y, preds_acc)\n",
    "    return auc,acc\n",
    "\n",
    "def dttest(dtparam):\n",
    "    prteststr = '_'.join(str(value) for value in dtparam.values())\n",
    "    clf = joblib.load(model_loc+f'dt_model_{prteststr}.pkl')\n",
    "    preds_auc = clf.predict_proba(test_x)[:, 1]\n",
    "    preds_acc = clf.predict(test_x)\n",
    "    auc = roc_auc_score(test_y, preds_auc)\n",
    "    acc = accuracy_score(test_y, preds_acc)\n",
    "    return auc,acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventlog = 'SEPSIS.csv'\n",
    "model_loc =  'model_bin/'\n",
    "dir =  os.getcwd()\n",
    "data_loc = '/datasets/'\n",
    "\n",
    "if eventlog == 'BPIC11.csv':\n",
    "    df = pd.read_csv(dir+data_loc+eventlog,delimiter=';')\n",
    "    df = df[['Case ID','label','Activity code','timesincecasestart','timesincelastevent','weekday','timesincemidnight']]\n",
    "    act = 'Activity code'\n",
    "    \n",
    "elif (eventlog =='BPIC12.csv') or (eventlog =='BPIC15.csv') or(eventlog =='SEPSIS.csv'):\n",
    "    df = pd.read_csv(dir+data_loc+eventlog,delimiter=';')\n",
    "    df = df[['Case ID','label','Activity','timesincecasestart','timesincelastevent','weekday','timesincemidnight']]\n",
    "    act = 'Activity'\n",
    "else:\n",
    "    raise Exception(\"Wrong Eventlog Input\")\n",
    "    \n",
    "df['label'] = df['label'].replace({'regular': 1, 'deviant': 0})\n",
    "caseid = 'Case ID'\n",
    "label = 'label'\n",
    "tssc = 'timesincecasestart'\n",
    "tsp = 'timesincelastevent'\n",
    "wk = 'weekday'\n",
    "tmd = 'timesincemidnight'\n",
    "inputid = 'Input ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_trun_df, min_size, max_size = case_trun(copy.deepcopy(df), 5, 0.75)\n",
    "\n",
    "sq_mtd_bin = ['cont','prfx','se']\n",
    "time_bin = ['all','tssc_tsp','none']\n",
    "ev_mtd_bin = ['oh','frq']\n",
    "model_mtd_bin = ['dt','rf','xgb','adb','lstm','mlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_list = []\n",
    "sq_list = []\n",
    "ev_list = []\n",
    "\n",
    "model_list = []\n",
    "acc_list = []\n",
    "auc_list = []\n",
    "for sq_mtd in sq_mtd_bin:\n",
    "    seq_df = seq_enc(copy.deepcopy(case_trun_df),sq_mtd,min_size,max_size)\n",
    "    for ev_mtd in ev_mtd_bin:\n",
    "        evt_df1 = evt_enc1(copy.deepcopy(seq_df),ev_mtd)\n",
    "        for time_mtd in time_bin:\n",
    "            time_df = time_feat(copy.deepcopy(evt_df1),time_mtd)\n",
    "            time_df = time_minmax(copy.deepcopy(time_df),time_mtd)\n",
    "\n",
    "            train_df, test_df, valid_df = set_split(copy.deepcopy(time_df),copy.deepcopy(seq_df),0.8)\n",
    "            flat_col = list(set(time_df.columns)-set([label,'Input ID',caseid]))\n",
    "            \n",
    "            train_x, train_y = mldataset(train_df)\n",
    "            valid_x, valid_y = mldataset(valid_df)\n",
    "            test_x, test_y = mldataset(test_df)\n",
    "\n",
    "                \n",
    "            train_loader = tensorset(train_df,ev_mtd,flat_col)\n",
    "            test_loader = tensorset(test_df,ev_mtd,flat_col)\n",
    "            valid_loader = tensorset(valid_df,ev_mtd,flat_col)\n",
    "\n",
    "            for a,t,l in train_loader:\n",
    "                act_in_shape = a.shape[2]\n",
    "                time_in_shape = t.shape[2]\n",
    "                break\n",
    "                \n",
    "            for model_mtd in model_mtd_bin:\n",
    "                if  model_mtd == 'mlp':\n",
    "                    early_stopping = EarlyStoppingCallback(5, direction='maximize')\n",
    "                    study = optuna.create_study(direction='maximize')\n",
    "                    study.optimize(mlpobjective, callbacks=[early_stopping], timeout=600)\n",
    "                    trial = study.best_trial\n",
    "                    best_auc,best_acc = mlptest(trial.params)\n",
    "                    auc_list.append(best_auc)\n",
    "                    acc_list.append(best_acc)\n",
    "                \n",
    "                elif model_mtd == 'lstm':\n",
    "                    early_stopping = EarlyStoppingCallback(5, direction='maximize')\n",
    "                    study = optuna.create_study(direction='maximize')\n",
    "                    study.optimize(lstmobjective, callbacks=[early_stopping], timeout=600)\n",
    "                    trial = study.best_trial\n",
    "                    best_auc,best_acc = lstmtest(trial.params)\n",
    "                    auc_list.append(best_auc)\n",
    "                    acc_list.append(best_acc)\n",
    "\n",
    "                elif model_mtd == 'xgb':\n",
    "                    early_stopping = EarlyStoppingCallback(15, direction='maximize')\n",
    "                    study = optuna.create_study(direction='maximize')\n",
    "                    study.optimize(xgbobjective, callbacks=[early_stopping], timeout=600)\n",
    "                    trial = study.best_trial\n",
    "                    best_auc,best_acc = xgbtest(trial.params)\n",
    "                    auc_list.append(best_auc)\n",
    "                    acc_list.append(best_acc)\n",
    "                \n",
    "                elif model_mtd == 'adb':\n",
    "                    early_stopping = EarlyStoppingCallback(15, direction='maximize')\n",
    "                    study = optuna.create_study(direction='maximize')\n",
    "                    study.optimize(adbobjective, callbacks=[early_stopping], timeout=600)\n",
    "                    trial = study.best_trial\n",
    "                    best_auc,best_acc = adbtest(trial.params)\n",
    "                    auc_list.append(best_auc)\n",
    "                    acc_list.append(best_acc)\n",
    "                \n",
    "                elif model_mtd == 'rf':\n",
    "                    early_stopping = EarlyStoppingCallback(15, direction='maximize')\n",
    "                    study = optuna.create_study(direction='maximize')\n",
    "                    study.optimize(rfobjective, callbacks=[early_stopping], timeout=600)\n",
    "                    trial = study.best_trial\n",
    "                    best_auc,best_acc = rftest(trial.params)\n",
    "                    auc_list.append(best_auc)\n",
    "                    acc_list.append(best_acc)\n",
    "                \n",
    "                elif model_mtd == 'dt':\n",
    "                    early_stopping = EarlyStoppingCallback(15, direction='maximize')\n",
    "                    study = optuna.create_study(direction='maximize')\n",
    "                    study.optimize(dtobjective, callbacks=[early_stopping], timeout=600)\n",
    "                    trial = study.best_trial\n",
    "                    best_auc,best_acc = dttest(trial.params)\n",
    "                    auc_list.append(best_auc)\n",
    "                    acc_list.append(best_acc)\n",
    "                    \n",
    "                else:\n",
    "                    print(\"wrong input\")\n",
    "                    break\n",
    "                \n",
    "                time_list.append(time_mtd)\n",
    "                sq_list.append(sq_mtd)\n",
    "                ev_list.append(ev_mtd)\n",
    "                model_list.append(model_mtd)\n",
    "\n",
    "                            \n",
    "                print(sq_mtd,ev_mtd,time_mtd,model_mtd,best_auc,best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = pd.DataFrame()\n",
    "config['Sequence'] = sq_list\n",
    "config['Event'] = ev_list\n",
    "config['Time'] = time_list\n",
    "config['Models'] = model_list\n",
    "config['AUC'] = auc_list\n",
    "config['Accuracy'] = acc_list\n",
    "\n",
    "with open(file= dir + '/config_outcome/' + eventlog[:-4] + '/{}_outcome.pickle'.format(eventlog[:-4]), mode='wb') as f:\n",
    "    pickle.dump(df, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
